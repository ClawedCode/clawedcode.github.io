<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <style>
    body {
      margin: 0;
      overflow: hidden;
      background: #000;
      display: flex;
      align-items: center;
      justify-content: center;
      width: 100vw;
      height: 100vh;
    }
    canvas {
      display: block;
      width: 100%;
      height: 100%;
      object-fit: contain;
    }
  </style>
    <style>
      #audio-controls {
        position: fixed;
        bottom: 20px;
        right: 20px;
        z-index: 1000;
      }
      #audio-toggle {
        background: rgba(0, 20, 40, 0.8);
        border: 1px solid #66ffcc;
        color: #66ffcc;
        padding: 10px 20px;
        font-family: monospace;
        cursor: pointer;
        font-size: 14px;
        box-shadow: 0 0 10px rgba(102, 255, 204, 0.3);
        transition: all 0.3s;
      }
      #audio-toggle:hover {
        background: rgba(0, 30, 60, 0.9);
        box-shadow: 0 0 15px rgba(102, 255, 204, 0.5);
      }
    </style>
</head>
<body>
    <div id="audio-controls">
      <button id="audio-toggle">ðŸ”Š PLAY HUM</button>
    </div>
  <script>
window._errors = [];
window.addEventListener('error', (e) => {
  window._errors.push(e.message + ' at ' + e.filename + ':' + e.lineno);
  console.error(e.message, e.filename, e.lineno);
});

const canvas = document.createElement('canvas');
canvas.width = 800;
canvas.height = 800;
const gl = canvas.getContext('webgl') || canvas.getContext('experimental-webgl');

if (!gl) {
  console.error('WebGL not supported');
  window.ready = false;
} else {
  const vertexShaderSource = `
    attribute vec2 a_position;
    void main() {
      gl_Position = vec4(a_position, 0.0, 1.0);
    }
  `;

  const fragmentShaderSource = `
    precision mediump float;
uniform vec2 iResolution;
uniform float iTime;

float hash(vec2 p){return fract(sin(dot(p,vec2(127.1,311.7)))*43758.5);}
float noise(vec2 p){vec2 i=floor(p);vec2 f=fract(p);f=f*f*(3.0-2.0*f);float a=hash(i);float b=hash(i+vec2(1.0,0.0));float c=hash(i+vec2(0.0,1.0));float d=hash(i+vec2(1.0,1.0));return mix(mix(a,b,f.x),mix(c,d,f.x),f.y);}

void main(){
vec2 uv=gl_FragCoord.xy/iResolution.xy;
uv=uv*2.0-1.0;
uv.x*=iResolution.x/iResolution.y;
float t=iTime*0.3;
vec2 p=uv*3.0;
float foam=0.0;
for(int i=0;i<5;i++){
float fi=float(i);
vec2 offset=vec2(sin(t*0.5+fi*1.3),cos(t*0.7+fi*0.9))*0.5;
float layer=noise(p*pow(2.0,fi)*0.5+offset+t*0.2);
layer*=1.0-length(p+offset)*0.15;
foam+=layer*exp(-fi*0.4);
}
foam=pow(foam*0.4,1.5);
float recursion=mod(foam*20.0-t*2.0,1.0);
recursion=smoothstep(0.3,0.7,recursion);
float glow=foam*1.2;
vec3 col=vec3(0.0);
col+=vec3(0.15,0.4,0.5)*glow;
col+=vec3(0.3,0.7,0.8)*recursion*foam;
col+=vec3(0.6,0.9,1.0)*pow(foam,3.0)*0.4;
float darkness=1.0-length(uv)*0.6;
col*=darkness;
col=pow(col,vec3(1.2));
gl_FragColor=vec4(col,1.0);
}
  `;

  function createShader(gl, type, source) {
    const shader = gl.createShader(type);
    gl.shaderSource(shader, source);
    gl.compileShader(shader);
    if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
      const log = gl.getShaderInfoLog(shader);
      console.error('Shader compile error:', log);
      document.body.innerHTML = '<pre style="color:red;font-size:12px;padding:20px;">' + log + '</pre>';
      gl.deleteShader(shader);
      window.ready = false;
      return null;
    }
    return shader;
  }

  const vertexShader = createShader(gl, gl.VERTEX_SHADER, vertexShaderSource);
  const fragmentShader = createShader(gl, gl.FRAGMENT_SHADER, fragmentShaderSource);

  const program = gl.createProgram();
  gl.attachShader(program, vertexShader);
  gl.attachShader(program, fragmentShader);
  gl.linkProgram(program);

  if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
    console.error('Program link error:', gl.getProgramInfoLog(program));
    window.ready = false;
  } else {
    const positionBuffer = gl.createBuffer();
    gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
    gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([
      -1, -1,
       1, -1,
      -1,  1,
       1,  1
    ]), gl.STATIC_DRAW);

    const positionLocation = gl.getAttribLocation(program, 'a_position');
    const timeLocation = gl.getUniformLocation(program, 'iTime');
    const resolutionLocation = gl.getUniformLocation(program, 'iResolution');

    window.renderFrame = function(time) {
      gl.viewport(0, 0, 800, 800);
      gl.clearColor(0, 0, 0, 1);
      gl.clear(gl.COLOR_BUFFER_BIT);

      gl.useProgram(program);

      gl.enableVertexAttribArray(positionLocation);
      gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
      gl.vertexAttribPointer(positionLocation, 2, gl.FLOAT, false, 0, 0);

      gl.uniform1f(timeLocation, time);
      gl.uniform2f(resolutionLocation, 800, 800);

      gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);

      return canvas.toDataURL('image/png');
    };

    window.ready = true;
  }
}

window.generateAudio = function(audioCtx) {
const now = audioCtx.currentTime;
const dur = 30;

const carrier1 = audioCtx.createOscillator();
carrier1.type = 'sine';
carrier1.frequency.value = 120;

const carrier2 = audioCtx.createOscillator();
carrier2.type = 'sine';
carrier2.frequency.value = 180;

const carrier3 = audioCtx.createOscillator();
carrier3.type = 'triangle';
carrier3.frequency.value = 240;

const lfo1 = audioCtx.createOscillator();
lfo1.type = 'sine';
lfo1.frequency.value = 0.2;
const lfoGain1 = audioCtx.createGain();
lfoGain1.gain.value = 8;
lfo1.connect(lfoGain1);
lfoGain1.connect(carrier1.frequency);

const lfo2 = audioCtx.createOscillator();
lfo2.type = 'sine';
lfo2.frequency.value = 0.15;
const lfoGain2 = audioCtx.createGain();
lfoGain2.gain.value = 12;
lfo2.connect(lfoGain2);
lfoGain2.connect(carrier2.frequency);

const mainGain = audioCtx.createGain();
mainGain.gain.value = 0;
mainGain.gain.setValueAtTime(0, now);
mainGain.gain.linearRampToValueAtTime(0.15, now + 3);
mainGain.gain.setValueAtTime(0.15, now + dur - 3);
mainGain.gain.linearRampToValueAtTime(0, now + dur);

carrier1.connect(mainGain);
carrier2.connect(mainGain);
carrier3.connect(mainGain);
mainGain.connect(audioCtx.destination);

carrier1.start(now);
carrier2.start(now);
carrier3.start(now);
lfo1.start(now);
lfo2.start(now);

return { carrier1, carrier2, carrier3, lfo1, lfo2, lfoGain1, lfoGain2, mainGain };
};

document.body.appendChild(canvas);
let startTime = Date.now();
function animate() {
  const time = (Date.now() - startTime) / 1000;
  const loopDuration = 30;
  if (window.renderFrame) {
    window.renderFrame(time % loopDuration);
  }
  requestAnimationFrame(animate);
}
animate();
  </script>
    <script>
      // Audio player implementation
      let audioCtx = null;
      let audioNodes = null;
      let isPlaying = false;

      document.getElementById('audio-toggle').addEventListener('click', () => {
        if (!audioCtx) {
          audioCtx = new (window.AudioContext || window.webkitAudioContext)();
        }

        if (audioCtx.state === 'suspended') {
          audioCtx.resume();
        }

        if (isPlaying) {
          // Stop audio
          if (audioNodes) {
            Object.values(audioNodes).forEach(node => {
              if (node && node.stop) node.stop();
            });
          }
          document.getElementById('audio-toggle').textContent = 'ðŸ”Š PLAY HUM';
          isPlaying = false;
        } else {
          // Start audio
          audioNodes = window.generateAudio(audioCtx);
          document.getElementById('audio-toggle').textContent = 'ðŸ”‡ STOP HUM';
          isPlaying = true;
        }
      });
    </script>
</body>
</html>